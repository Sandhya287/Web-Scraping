{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a88f406-e45e-4ca8-b3c2-e0b52cccd9d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q1. What is Web Scraping? Why is it Used? Give three areas where Web Scraping is used to get data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92739e5d-cb1d-4a0e-87f1-3dedbab5ed53",
   "metadata": {},
   "outputs": [],
   "source": [
    "Web scraping is a technique used to extract large amounts of data from websites. It automates the process of collecting data from the internet, where the data is extracted and saved to a local file or database for further analysis or use. This method is used because it is efficient, saves time, and can retrieve data not readily available through APIs or other methods.\n",
    "\n",
    "Three areas where web scraping is used include:\n",
    "\n",
    "1.Market Research: Businesses scrape websites to gather data on prices, products, and consumer sentiment, which is crucial for competitive analysis and understanding market trends.\n",
    "2.Data Journalism: Journalists use web scraping to collect information from various sources for news stories, especially for data-driven journalism.\n",
    "3.Real Estate: Web scraping is used to collect data on property listings, prices, and market trends, aiding in market analysis and decision-making for buyers, sellers, and real estate companies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19c6e47c-b575-443f-a5ff-c2909458a842",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q2. What are the different methods used for Web Scraping?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c253e02e-2dd8-41cf-8cf3-b8f4427ca8e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "Several methods are used for web scraping, including:\n",
    "\n",
    "HTML Parsing: Involves analyzing an HTML document and extracting relevant information. Tools like Beautiful Soup in Python are used for this.\n",
    "DOM Parsing: Involves accessing the Document Object Model (DOM) of the webpage using scripting languages like JavaScript.\n",
    "XPath: A language for navigating through elements and attributes in an XML document. It is used for selecting nodes in an HTML document.\n",
    "Web Browser Automation: Tools like Selenium are used to automate browser actions to scrape data.\n",
    "APIs: Some websites offer APIs for data extraction, which can be a more efficient and reliable method of scraping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba71a16c-7889-4097-ba4f-38aa74e926a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q3. What is Beautiful Soup? Why is it used?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b328758-99ef-486d-b08a-0dd91bc9381b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Beautiful Soup is a Python library designed for web scraping purposes. It is used to parse HTML and XML documents, making it easier to scrape data from web pages. It creates a parse tree from page source code that can be used to extract data easily and efficiently. Beautiful Soup is popular due to its ease of use and ability to handle various markup formats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e6f1f1a-e735-4f94-93a7-02a791589fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q4. Why is flask used in this Web Scraping project?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a06d43-a31b-440d-b53e-3999ea0654c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "Flask, a micro web framework written in Python, is used in web scraping projects to create a web application interface. It is used because it is lightweight, easy to use, and allows for the integration of web scraping functionality into a web application. Flask can be used to develop APIs, web services, or a user interface for scraping scripts, making the data scraping process interactive and accessible to users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48fa1ea7-6cd7-465a-86b6-f219d91e31f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q5. Write the names of AWS services used in this project. Also, explain the use of each service."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0caf1cfa-e605-4ae1-ab5a-3eab79b5db45",
   "metadata": {},
   "outputs": [],
   "source": [
    "In a web scraping project, several AWS services might be used, such as:\n",
    "\n",
    "Amazon EC2: Provides scalable computing capacity in the Amazon Web Services cloud. Used for hosting the scraping scripts or applications.\n",
    "AWS Lambda: A serverless compute service that runs code in response to events. It can be used to trigger scraping scripts based on schedule or other AWS service events.\n",
    "Amazon S3: An object storage service used to store and retrieve any amount of data at any time. It can be used for storing scraped data.\n",
    "Amazon RDS: A relational database service for managing databases. Used to store and manage structured data obtained from web scraping.\n",
    "AWS Glue: A fully managed extract, transform, and load (ETL) service. It can be used for data preparation and loading after scraping.\n",
    "Each of these services contributes to different aspects of a web scraping project, from data extraction and storage to processing and management."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
